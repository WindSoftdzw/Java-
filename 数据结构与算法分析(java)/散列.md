# 散列

###### 2019年4月28日

###### 16:15

### 一般想法
理想的散列表数据结构只不过是一个包含一些项的具有固定大小的数组。通常查找是对项的某个部分进行的。这部分就叫做关键字**关键字**。例如，项可以由一个串和其他一些数据域组成。我们把表的大小叫作TableSize，并将其理解为散列数据结构的一部分，而不仅仅是浮动于全局的某个变量。通常的习惯是让表从0到TableSize - 1变化；  
每个关键字被映射到从0到TableSize - 1这个范围中的某个数，并且被放到适当的单元中。这个映射就叫作散列函数，理想情况下它应该计算起来简单，并且应该保证任何两个不同的关键字映射到不同的单元。不过，这是不可能的，因为单元的数目是有限的，而关键字实际上是用不完的。因此，我们寻找一个散列函数，该函数要在单元之间均匀地分配关键字。
### 散列函数
如果输入的关键字是整数，则一般合理的方法就是直接返回Key mod Tablesize，除非Key碰巧具有某些不合乎需要的性质。在这种情况下，散列函数的选择需要仔细考虑。例如，若表的大小是10而关键字都以0为个位，则此时上述标准的散列函数就是一个不好的选择。为了避免上面上面那样的情况，好的办法通常是保证表的大小是素数。当输入的关键字是随机整数时，散列函数不仅计算起来简单而且关键字的分配也很均匀。  
通常，关键字时字符串；在这种情况下，散列函数需要仔细地选择。一种选择方法是把字符串中字符的ASCLL码值加起来。
```java
public static int hash( String key, int tableSize )
{
  int hashVal = 0;
  
  for( int i = 0; i < key.length(); i++)
    hashVal += key.charAt(i);
    
  return hashVal % tableSize;
}
```
上面的散列函数实现起来简单而且能够很快的计算出答案。不过，如果表很大，函数将不会很好的分配关键字。
另一个散列函数假设Key至少有3个字符。值27表示英文字母表的字母外加一个空格的个数，而729是27^2。该函数只考查前三个字符，但是，假设它们是随机的，而表的大小是10007，那么我们就会得到一个合理的均衡分布。可是不巧的是，英文不是随机的。虽然三个字符有26^3 = 17576种可能，但查验足够大的词典却揭示：3个字母的不同组合实际只有2851。即使这些组合没有任何冲突，也不过只有表的28%被真正散列到。因此，虽然很容易计算，但是当散列表具有合理的大小的时候这个函数还是不合适的。
```java
public static int hash( String key, int tableSize )
{
  return( key.charAt(0) + 27 * key.charAt(1) + 729 * key.charAt(2) ) % tableSize;
}
```
散列函数的第三种尝试：这个散列函数涉及关键字中的所有字符，并且一般可以分布的很好（它计算$\sum_{i=0}^{KeySize-1}{Key[KeySize-i-1]*37^i}$,并将结果限制在适当的范围）。程序根据Honer法则计算一个多项式函数。  
这个散列利用到事实：允许溢出。这可能会引进负的数，因此在末尾有附加的测试。  
下面散列函数就表的分布而言未必是最好的，但确实具有极其简单的优点而且速度也很快。如果关键字特别长，那么该散列函数计算起来将会花费过多的时间。在这种情况下通常的经验是不使用所有的字符。此时关键字的长度和性质将影响选择。有些程序员选择通过只使用奇数位置上的字符来实现它们的散列函数，用计算散列函数节省下的时间来补偿由此产生的对均匀地分布的函数的轻微干扰。

```java
public static int hash( String key, int tableSize )
{
  int hashVal = 0;
  
  for( int i = 0; i < key.length(); i++; )
    hashVal = 37 * hashVal + key.charAt(i);
    
  hashVal %= tableSize;
  if( hashVal < 0 )
    hashVal += tableSize;
    
  return hashVal;
}
```
剩下的主要编程细节是解决冲突的消除问题。如果当一个元素被插入时与一个已经插入的元素散列到相同的值，那么就产生一个冲突，这个冲突需要消除。解决这种冲突的方法有几种，其中最简单的两种：分离链接法和开放定址法。
### 分离链接法
解决冲突的第一种方法通常的叫作**分离链接法**，其做法是将散列到同一个值得所有元素保留到一个表中。我们可以使用标准库表的实现方法。如果空间很紧，则更可取的方法是避免使用它们（因为这些表是双向链接的并且浪费空间）。我们假设关键字是前10个完全平方数并设散列函数就是hash(x) = x mod 10。
为执行一次查找，我们使用散列函数来确定究竟遍历哪个链表。然后我们再在被确定的链表中执行一次查找。为执行 insert，我们检查相应的链表看看该元素是否已处在适当的位置（如果允许插入重复元，那么通常要留出一个额外的域，这个域当出现匹配事件时增1）。如果这个元素是个新元素，那么它将被插入到链表的前端，这不仅因为方便，还因为常常发生这样的事实：新近插入的元素最有可能不久又被访问。  
实现分离链接法所需要的类架构如下所示。散列表存储一个链表数组，它们在构造方法种被指定。
```java
public class SeparateChainingHashTable<AnyType>
{
  public SeparateChainingHashTable()
    {}
  public SeparateChainingHashTable( int size )
    {}
    
  public void insert( AnyType x )
    {}
  public void remove( AnyType x )
    {}
  public boolean contains( AnyType x )
    {}
  public void makeEmpty()
    {}
    
  private static final int DEFAULT_TABLE_SIZE = 101;
  
  private List<AnyType> [] theLists;
  private int currentSize;
  
  private void rehash()
    {}
  private int myhash( AnyType x )
    {}
    
  private static int nextPrime( int n )
    {}
  private static boolean isPrime( int n )
    {}
}
```
就像二叉查找树只对那些是Comparable的对象工作一样，以上的散列表只对遵守确定协议的那些对象工作。在Java中这样的对象必须提供适当equals方法和返回一个int型量的hashCode方法，此时，散列表把这个int型量通过myHash转成适当的数组下标，如下所示。
```java
private int myhash( AnyType x )
{
  int hashVal = x.hashCode();
  
  hashVal %= theLists.length;
  if( hashVal < 0 )
    hashVal += theLists.length;
    
  return hashVal;
}
```
下方代码解释了Employee类，可以将其存放在一个散列表中。
```java
public class Employee
{
  public boolean equals( Object rhs )
    { return rhs instanceof Employee && name.equals( ( (Employee)rhs) .name ); }
    
  public int hashCode()
    { return name.hashCode(); }
    
  private String name;
  private double salary;
  private int seniority;
```
类Employee提供equals方法和基于Employee名字的的hashCode方法。Employee类的hashCode通过使用标准String类中定义的hashCode来工作。  
实现contains、insert和remove的例程如下所示。
```java
public boolean contains( AnyType x )
{
  List<AnyType> whichList = theLists[ myhash(x) ];
  return whichList.contains(x);
}

public void insert( AnyType x )
{
  List<AnyType> whichList = theList[ myhash(x) ];
  if( !whichList.contains(x) )
  {
    whichList.add(x);
    
    if( ++currentSize > theLists.length )
      rehash();
  }
}

public void remove( AnyType x )
{
  List<AnyType> whichList = theLists[ myhash(x) ];
  if( whichList.contains(x) )
  {
    whichList.remove(x);
    currentSize--;
  }
}
```
在插入函数中，如果被插入的项已存在，那么我们不执行任何操作；否则，我们将其放入链表中。该元素可以被放到链表的任何位置；在我们的情形下使用add方法是最方便的。
```java
/**
 *分离链接散列表的构造方法和makeEmpty方法
 */
public SeparateChainingHashTable()
{
  this( DEFAULT_TABLE_SIZE);
}

public SeparateChainingHashTable( int size )
{
  theLists = new LinkedList[ nextPrime( size ) ];
  for( int i = 0; i < theLists.length; i++ )
    theLists[i] = new LinkedList<>();
  
}

public void makeEmpty()
{
  for( int i = 0; i < theLists.length; i++ )
    theLists[i].clear();
  currentSize = 0;
}
```
除链表外，任何方案都可以解决冲突现象；一棵二叉查找树或甚至另一个散列表都将胜任这个工作，但是，我们期望如果散列表是大的并且散列函数是好的，那么所有的链表都应该是短的，从而任何复杂的尝试就都不值得考虑了。  
我们定义散列表的装填因子$\lambda$为散列表中的元素个数对该表大小的比。在上面的例子中，$\lambda$ = 1.0。链表的平均长度为$\lambda$。执行一次查找所需要的工作是计算散列函数值所需要的常数时间加上遍历链表所用的时间。在一次不成功的查找中，要考查的节点数平均为$\lambda$。一次成功的查找则需要遍历大约1 + ($\lambda$/2)个链。为了看清这一点，注意被搜索的链表包含一个存储匹配的节点再加上0个或更多个其他的节点。在N个元素的散列表以及M个链表中“其他节点”的期望个数为(N-1)/M=$\lambda$-1/M，它基本上就是$\lambda$，因为假设M是大的。平均看来，一半的“其他”节点被搜索到，再结合匹配节点，我们得到1+$\lambda$/2个节点的平均查找代价。这个分析指出，散列表的大小实际上并不重要，而装填因子才是重要的。分离链表散列法的一般法则是使得表的大小与预料的元素个数大致相等。

### 不用链表的散列表
分离链接散列算法的缺点是使用一些链表。给新单元分配地址需要时间，导致算法的速度有些减慢，同时算法实际上还要求对第二种数据结构的实现。另有一种不用链表解决冲突的方法是尝试另外一些单元，直到找出空的单元为止。单元$h_0(x),h_1(x),h_2(x)$，···相继被试选，其中$h_i(x) = ( hash(x)+f(i) )$ mod TableSize,且f(0) = 0。函数f是冲突解决办法。因为所有的数据都要置入表中，所以这种解决方案所需要的表要比分离链接散列的表大。一般来说，对于不使用分离链接的散列表来说，其装填因子应该低于$\lambda$ = 0.5。我们把这样的表叫作**探测散列表**。

###### 线性探测法
在线性探测法中，函数f是i的线性函数，典型情形是f(i) = i。这相当于相继探测逐个单元以查找一个空单元。只要表足够大，总能够找到一个自由单元，但是这样花费的时间是相当多的。更糟的是，即使表相对较空，这样占据的单元也会开始形成一些区块，其结果称为**一次聚集**，就是说，散列到区块中的任何关键字都需要多次试选单元才能够解决冲突，然后该关键字被添加到相应的区块中。  
可以证明，使用线性探测的预期探测次数对于插入和不成功的查找来说大约为$1/2(1+1/(1-\lambda)^2)$，而对于成功的查找来说则是$1/2(1+1/(1-\lambda))$。从程序中容易看出，插入和不成功查找需要相同次数的探测。成功查找应该比不成功查找平均花费较少的时间。  
如果聚集不算是问题，那么对应的公式就不难得到。我们假设有一个很大的散列表，并设每次探测都与前面的探测无关。对于随机冲突解决方法而言，这些假设是成立的，并且当$\lambda$不是非常接近于1时也是合理的。首先，我们导出在一次不成功查找中探测的期望次数，而这正是直到我们找到一个空单元的探测的期望次数。由于空单元所占的份额为$1-\lambda$，因此我们预计要探测的单元数是$1/(1-\lambda)$ 。一次成功查找的探测次数等于该特定元素插入时所需要的探测次数。当一个元素被插入时，可以看成进行一次不成功查找结果。因此，我们可以使用一次不成功查找的开销来计算一次成功查找的平均开销。  
$\lambda$从0到当前值之间变化，因此早期的插入操作开销较少，从而将平均开销拉低。我们可以通过使用积分计算插入时间平均值的方法来估计平均值。  
$$
I(\lambda) = \frac{1}{\lambda}\int_0^\lambda{\frac{1}{1-x}dx} = \frac{1}{\lambda}ln\frac{1}{1-\lambda}
$$
这些公式显然优于线性探测那些相应的公式。聚集不仅是理论上的问题，而且实际上也发生在具体的实现中。  
如果$\lambda=0.75$，那么上面的公式指出在线性探测中一次插入预计8.5次探测。如果$\lambda=0.9$，则预计为50次探测。假如聚集不是问题，那么这可与相应的装填因子的4次和10次探测相比。从这些公式看到，如果表可以有多于一半被填满的话，那么线性探测就不是个好方法。然而，如果$\lambda$ = 0.5，那么插入操作平均只需要2.5次探测，并且对于成功的查找平均只需要1.5次探测。
###### 平方探测法
平方探测是消除线性探测中一次聚集问题的冲突解决办法。平方探测就是冲突函数为二次的探测方法。流行的选择是$f(i) = i^2$。  
对于线性探测，让散列表几乎填满元素并不是一个好主意，因为此时表的性能会降低。对于平方探测情况甚至更糟：一旦表被填充超过一半，当表的大小不是素数时甚至在表被填充一半之前，就不能保证一次找到空的单元了。这是因为最多有表的一半可以用作解决冲突的备选位置。
**定理5.1**  如果使用平方探测，且表的大小是素数，那么当表至少有一半是空的时候，总能够插入一个新的元素  
即使表被填充的位置仅仅比一半多一个，那么插入都有可能失败。另外，表的大小是素数也非常重要。如果表的大小不是素数，则备选单元的个数可能会锐减。  
在探测散列表中标准的删除操作不能执行，因此相应的单元可能已经引起过冲突，元素绕过它存在了别处。因此，探测散列表需要懒惰删除，不过在这种情况下实际上并不存在所意味的懒惰。  
```java
public class QuadraticProbingHashTable<AnyType>
{
  /*
   散列无参构造方法，默认大小为11
  **/
  public QuadraticProbingHashTable()
  {
    this( DEFAULT_TABLE_SIZE );
  }
  /*
   散列有参构造方法，大小为参数size
  **/
  public QuadraticProbingHashTable( int size )
  {
    allocateArray( size );
    makeEmpty;
  }
  /*
   清空散列方法
  **/
  public void makeEmpty()
  {
    currentSize = 0;
    for(int i = 0; i < array.length; i++)
      array[i] = null;
  }
  /*
   检查是否包含元素方法，
  **/
  public boolean contains( AnyType x )
  {
    int currentPos = findPos( x );
    return isActive( currentPos );
  }
  /*
   给定元素值插入元素方法
  **/
  public void insert( AnyType x )
  {
    int currentPos = findPos( x );
    if( isActive( currentPos ) )
      return;
      
    array[ currentPos ] = new HashEntry<>( x, true );
    
    if( currentSize > array.length/2 )
      rehash();
  }
  /*
   给定元素值移除元素方法
  **/
  public void remove( AnyType x )
  {
    int currentPos = findPos( x );
    if( isActive( currentPos ) )
      array[ currentPos ].isActive = false;
  }
  /*
   散列节点对象构造方法
  **/
  private static class HashEntry<AnyType>
  {
    public AnyType element;
    public boolean isActive;
    
    public HashEntry( AnyType e )
     { this( e, true ); }
     
   public HashEntry( AnyType e, boolean i )
     { element = e; isActive = i; }
  }
  
  private static final int DEFAULT_TABLE_SIZE = 11;
  
  private HashEntry<AnyType> [] array;
  private int currentSize;
  
  private void allocateArray( int arraySize )
    {
      array = new HashEntry[ nextPrime( arraySize ) ];
    }
  /*
   判断元素是否为激活状态
  **/
  private boolean isActive( int currentPos )
    {
      return array[ currentPos ] != null && array[ currentPos ].isActive;
    }
 /*
   发现位置方法，while循环中快速计算平方探测
  **/
  private int findPos( AnyType x )
    {
      int offset = 1;
      int currentPos = myhash( x );
      
      while( array[ currentPos ] != null && !array[ currentPos ].element.equals( x ) )
      {
        currentPos += offset;
        offset += 2;
        if( currentPos >= array.length )
          currentPos -= array.length;
      }
      
      return currentPos;
    }
  private void rehash()
    {}
    
  private int myhash( AnyType x )
    {}
  private static int nextPrime( int n )
    {}
  private static boolean isPrime( int n )
    {}
}

```
虽然平方探测排除了一次聚集，但是散列到同一位置上的那些元素将探测相同的备选单元。这叫作**二次聚集**。二次聚集是理论上的一个小缺憾。模拟结果指出，对每次查找，它一般要引起另外的少于一半的探测。下面的技术将会排除这个缺憾，不过要付出计算一个附加的散列函数的代价。
###### 双散列
对于双散列，一种流行的选择是$f(i)= i * hash_2(x)$。这个公式是说，我们将第二个散列函数应用到x并在距离$hash_2(x),2hash_2(x),···$等处探测。$hash_2(x)$选择得不好将会是灾难性的。函数一定不要算得0值。另外，保证所有的单元都能被探测到也是很重要得。  
###  再散列
对于使用平方探测的开放定址散列法，如果散列表填的太慢，那么操作的运行时间将开始消耗过长，且插入操作可能失败。这可能发生在有太多的移动和插入混合的场合。此时一种解决方法是建立另外一个大约两倍大的表（而且使用一个相关的新散列函数），扫描整个原始散列表，计算每个元素的新散列值并将其插入到新表中。  
整个操作就叫做**再散列**。显然这是一种开销非常大的操作；其运行时间为O(N)，因为有N个元素要再散列而表的大小约为2N，不过，由于不是经常发生，因此实际效果根本没那么差。特别是在最后的再散列之前必然已经存在N/2次insert，因此添加到每个插入上的花费基本上是一个常数开销。如果这种数据结构是程序的一部分，那么其影响是不明显的。另一方面，如果再散列作为交互系列的一部分运行，那么插入引起再散列的不幸用户将会感到速度减慢。  
再散列可以用平方探测以多种方法实现。一种做法是只要表满到一半就再散列。另一种极端的方法是只有当插入失败时才再散列。第三种方法即途中策略：当散列表到达某一个装填因子时进行再散列。由于随着装填因子的增长散列表的性能确实下降，因此，以好的截止手段实现的第三种策略，可能是最好的策略。  
### 标准库中的散列表
标准库包括Set和Map的散列表的实现，即HashSet类和HashMap类。HashSet中的项必须提供equals方法和hashCode方法，HashSet和HashMap通常是用分离链接散列实现的。  
如果这些表项石佛可以依有序方式查看这一点并不重要，那么这些类可以使用。  
HashMap的性能通常优于TreeMap，不过不按这两种方式编写代码很难有把握肯定。因此在HashMap或TreeMap可以接受的情况下，更可取的方法是：使用接口类型Map进行变量的声明，然后，将TreeMap的实例变成HashMap的实例并进行计时测试。  
在Java中，能够被合理的插入到一个HashSet中去或是所谓关键字被插入到HashMap中去的那些库类型已经被定义了equals和hashCode方法。特别是String类中有一个hashCode方法。因为散列表操作中费时多的部分就是计算hashCode方法，所以在String类中的hashCode方法包含一个重要的优化：每个String对象内部都存储它的hashCode值。该值初始为0，但若hashCode被调用，那么这个值就被记住。因此，如果hashCode对同一个String对象被第2次计算，我们则可以避免昂贵的重新计算。这个技巧叫作**闪存散列代码**，并且表示另一种经典的时空交换。下面代码显示闪存散列代码String类的一种实现。
```java
public final class String
{
  public int hashCode()
  {
    if( hash != 0 )
      return hash;
      
    for( int i = 0; i < length(); i++ )
      hash = hash * 31 + (int) charAt(i);
    
    return hash;
  }
  
  private int hash = 0;
}
```
闪存散列代码之所以有效，只是因为String类是不可改变的：要是String允许变化，那么它就会使hashCode无效，而hashCode就只能重置回0。虽然两个具有相同状态的String对象的hashCode必须独立计算，但是，存在许多情况使同一个String对象的散列代码总是被查询。闪存散列代码有用的一种情况是在再散列期间发生，因为在再散列中所涉及的所有String对象的散列代码都已经闪存过。
### 最坏情况下O(1)访问的散列表
目前我们讨论过的散列表都具有的性质是，当有合理的装填因子和合适的散列函数时，可以期望插入、删除和查找的平均花销都是O(1)。  
对分离链接法而言，假设装填因子为1，这就是经典的**球盒问题**的一个版本：给定N个球，随机地放在N个盒子中，在装球最多的盒子里，球的个数的期望值是O(log N/log log N)，意即平均而言，我们期望部分查询会花费近乎对数的时间。对于探测散列表中的最长期望探测序列，也可观察到相似类型的上界。  
我们想要得到O(1)的最坏情形的花销。在某些应用中，如路由器和内存缓存的查找表的硬件实现，令查找具有确定的完成时间是特别重要的。假设我们事先知道N的值，于是不需要再散列。如果我们可以在插入的过程中重新排列各项，则查找的O(1)最坏情形花销是可以达到的。

###### 完美散列
为了简单起见，假设所有N项都事先知道。如果分离链接的实现可以保证每张表最多有常数多个项，问题就解决了。我们知道，如果多用一些表，则这些表的平均长度就会短一些，于是理论上讲，如果我们有充分多的表，则在相当高的概率下可以期待根本没有冲突！
但是这种方法存在两个基本的问题：首先，表的数量可能大得离谱；其次，即使有很多表，我们还是可能碰到坏运气。  
第二个问题原则上比较好处理。假设我们将表的个数选定为M(即令TableSize为M)，且令其充分大以保证没有冲突的概率至少是1/2。则如果检测到冲突，我们只要简单地把散列表清空，再用独立于第一个函数得不同的散列函数去式一下。如果仍然有冲突，我们就试第三个散列函数，以此类推。尝试次数的期望将最多是2，且全部可以可以归结为插入的成本。  
于是接下来我们只需要决定表的个数M的大小。不幸的是，M必须非常的，具体来说，$M = Ω (N^2)$。然而，如果$M = N^2$，那么我们可以证明散列表至少有1/2的概率是没有冲突的。
**定理：**  若N个球被放入$M = N^2$个盒子，则没有任何盒子装有超过1个球的概率不小于1/2
当然，使用$N^2$个表是不现实的。但是前面的分析暗示了另一种选择：只用N个盒子，但是用散列表去解决每个盒子的冲突，而不是用链表。因为期望每个盒子里有少量的球，所以给每个盒子用的散列表的大小可以是盒子容量的平方。  
按照最原始的思路，每个二级散列表将用一个不同的散列函数进行构造，直到没有冲突为止。如果产生的冲突次数高于要求的值，主散列表也可以被构建多次。这种方法称为**完美散列**。
**定理：**  若N个项被放入包含N个盒子的主散列表中，则二级散列表的总容量的期望值最多是2N。
###### 布谷鸟散列  
从之前的讨论可知，在球盒问题中，如果N个项被随机地投入N个盒子中，则盒子容量最大期望值是O(logN/log log N)。这个界已经久为人知，人们惊讶于一个明显更小的界被证明，即在每次投放时，如果随机选择两个盒子，将该项投入比较空的那个盒子，则最大的盒子容量仅是O(log log N)。
其中一种思路便是**布谷鸟散列**。在布谷鸟散列中，假设有N个项。我们维护两个分别超过半空的表，且有两个独立的散列函数，可以把每个项分配到每个表中的一个位置。布谷鸟散列保持不变的是一个项总会被存储在这两个位置之一。  
布谷鸟散列表中一次查找需要最多两次访问表，并且一旦该项被找到，删除就成了一项小事。
###### 布谷鸟散列的实现
实现布谷鸟散列需要一个散列函数的集合；简单地用hashCode生成散列函数地集合是没有意义的，因为任何hashCode冲突都将导致集合中所有散列函数冲突。下面给了一个可用于将散列函数族发送给布谷鸟散列的简单接口
```java
public interface HashFamily<AnyType>
{
  int hash( AnyType x, int which );
  int getNumberOfFuctions();
  void generateNewFunctions();
}
```
下面提供了一个类的框架。我们将编写一个经典实现的变种代码，允许任意数量的散列函数，仅用一个数组来让所有散列函数寻址。因此，我们的实现不同意经典的使用两个分开寻址的散列表的概念。  
我们指定最大的负载时0.4，如果表的装填因子快要超过此极限，就执行自动的表扩展。我们还定义了ALLOWED_REHASHES，如果替换过程执行了太长时间，它将指定我们要执行多少次再散列。在理论上，ALLOWED_REHASHES可以是无限的，因为我们期望需要再散列的次数只是一个小常数。实际上，这取决于一些因素，如散列函数的个数、散列函数的质量以及装填因子，再散列可能令过程显著变慢，因此进行表扩展可能是值得的，尽管这将花费空间。布谷鸟散列的数据表示是非常直截了当的：我们存储一个简单的数组、当前规模以及散列函数的集合，表示在一个HashFamily的实例中。我们还维护散列函数的个数，尽管这总是可以从HashFamily的实例中得到。
```java
public class CuckooHashTable<AnyType>
{
  public CuckooHashTable( HashFamily<? super AnyType> hf)
  {}
  public CuckooHashTable( HashFamily<? super AnyType> hf, int size )
  {}
  
  public void makeEmpty()
    { doClear(); }
    
  public boolean contains( AnyType x )
    {}
    
  private int myhash( AnyType x, int which )
    {}
    
  private int findPos( AnyType x )
    {}
    
  public boolean remove( AnyType x )
    {}
    
  public boolean insert( AnyType x )
    {}
    
  private void expand()
    {}
  
  private void rehash()
    {}
    
  private void doClear()
    {}
    
  private void allocateArray( int arraySize )
    { array = (AnyType[]) new Object[ arraySize ]; }
    
  private static final double MAX_LOAD = 0.4;
  private static final int ALLOWED_REHASHES = 1;
  private static final int DEFAULT_TABLE_SIZE = 101;
  
  private final HashFamily<? super AnyType> hashFunctions;
  private final int numHashFunctions;
  private AnyType [] array;
  private int currentSize;
}
```

下面给出了构造函数和doClear方法

```java
public CuckooHashTable( HashFamily<? super AnyType> hf )
{
  this( hf, DEFAULT_TABLE_SIZE);
}

public CuckooHashTable( HashFamily<? super AnyType> hf, int size )
{
  allocateArray( netPrime( size ) );
  doClear( );
  hashFunctions = hf;
  numHashFunctions = hf.getNumberOfFunctions( );
}

private void doClear( )
{
  currentSize = 0;
  for( int i = 0; i < array.length; i++ )
    array[ i ] = null;
}
```

下面给出一对私有方法。第一个myHash用于选择合适的散列函数，然后将它的值按比例对应到一个有效的数组下标。第二个findPos去查所有散列函数，返回包含x项的数组下标如果找不到x就返回-1。

```java
private int myhash( AnyType x, int which )
{
  int hashVal = hashFunctions.hash( x, which );
  
  hashVal %= array.length;
  if( hashVal < 0 )
    hashVal += array.length;
  
  return hashVal;
}

private int findPos( AnyType x )
{
  for( int i = 0; i < numHashFunctions; i++ )
  {
    int pos = myhash( x, i );
    if( array[ pos ] != null && array[ pos ].equals( x ) )
      return pos;
  }
}
```

下面的contains和remove函数都用到findPos方法来实现

```java
public boolean contains( AnyType x )
{
  return findPos( x ) != -1;
}
```

```java
public boolean remove( AnyType x )
{
  int pos = findPos( x );
  
  if( pos != -1 ) 
  {
    array[ pos ] = null;
    currentSize--;
  }
  
  return pos != -1;
}
```

在下面的例程中，我们可以看到基本的计划是检查该项是否已经存在，如果是的话就返回。否则，我们检查表是否已经满载，如果是的话就扩展之。最后我们调用一个辅助函数来干所有脏活累活。

```java
public boolean insert( AnyType x )
{
  if( contains( x ) )
    return false;
  
  if( currentSize >= array.length * MAX_LOAD )
    expand( );
  
  return insertHelperl( x );
}
```

在辅助函数中，我们声明一个变量rehashes来跟踪已经为这次插入尝试了多少次再散列。我们插入的函数是互递归的：在必要时，insert最终要调用rehash，而它最终又回头调用insert。所以为了代码简洁，rehash在外部声明。

```java
private int rehashes = 0;
private Random r = new Random( );

private boolean insertHelperl( AnyType x )
{
  final int COUNT_LIMIT = 100;
  
  while( true )
  {
    int lastPos = -1;
    int pos;
    
    for( int count = 0; count < COUNT_LIMIT; count++ )
    {
      for( int i = 0; i < numHashFunctions; i++ )
      {
        pos = myhash( x, i );
        
        if( array[ pos ] == null )
        {
          array[ pos ] = x;
          currentSize++;
          return true;
        }
      }
      
      
      int i = 0;
      do
      {
        pos = myhash( x, r.nextInt( numHashFunctions ) );
      } while( pos == lastPos && i++ < 5 );
      
      AnyType tmp = array[ lastPos = pos ];
      array[ pos ] = x;
      x = tmp;
    }
    
    if( ++rehashes > ALLOWED_REHASHES )
    {
      expand( );
      rehashes = 0;
    }
    else
      rehash( );
  }
}
```

当我们已经检测到要插入的项是不存在的时，我们检查是否有任何有效的位置是空着的，如果是的话，就把该项放到第一个可以用的位置，然后就完事了。否则，我们替换掉其中一个已经存在的项。然而，有一些棘手的问题：

* 替换第一项在实验中表现不好
* 替换最后一项在实现中表现不好
* 按序列替换项（即第一次用散列函数0，第二次用散列函数1）在实验中表现不好
* 纯粹随机地替换项在实验中表现不好，特别是对于只有两个散列函数地情况，这样往往会产生循环

为了缓解最后一个问题，我们维护被替换的最后一个位置，如果随机项是最后一个被替换的项，我们就选择一个新的随机项。这种做法有时候会无限循环，即当有两个散列函数，这两个散列函数都正巧探测同一个位置，而且该位置属于上次被替换的项的时候。所以我们将循环次数限制为5次。

下面给出expand和rehash方法。expand创建了一个更大的数组，但散列函数不变。rehash保持数组规模不变，但创建一个新的数组，用新选的散列函数去填充。

```java
private void expand( )
{
  rehash( (int) ( array.length / MAX_LOAD ) );
}

private void rehash( ) 
{
  hashFunctions.generateNewFunctions( );
  rehash( array.length );
}

private void rehash( int newLength )
{
  AnyType [ ] oldArray = array;
  allocateArray( nextPrime( newLength ) );
  currentSize = 0;
  
  for( AnyType str : oldArray )
    if( str != null )
      insert( str );
}
```

最后，StringHashFamily类提供了一套简单的处理字符串的散列函数。

```java
public class StringHashFamily implements HashFamily<String>
{
	private final int [ ] MUTIPLIERS;
	private final java.util.Random r = new java.util.Random( );
	
	public StringHashFamily( int d )
	{
		MUTIPLIERS = new int[ d ];
		generateNewFunctions( );
	}
	
	public int getNumberOfFunctions( )
	{
		return MULTIPLIERS.length;
	}
	
	public void generateNewFunctions( )
	{
		for( int i = 0; i < MULTIPLIERS.length; i++ )
			MULTIPLIERS[ i ] = r.nextInt( );
			
	}
	
	public int hash( String x, int which )
	{
		final int multiplier = MULTIPLIERS[ which ];
		int hashVal = 0;
		
		for( int i = 0; i < x.length( ); i++ )
			hashVal = multiplier * hashVal + x.charAt( i );
			
		return hashVal;
	}
}
```

布谷鸟散列的好处包括最坏情况下常数级的查找和删除时间，避免了懒惰删除和额外的数据以及并行化处理的可能性。然而，布谷鸟散列对于散列函数的选择极其敏感，使用低一些的装填因子或多于两个的散列函数似乎是一个合理的选择。

###### 跳房子散列

**跳房子散列**是一种新算法。它尝试改进经典的线性探测算法。在一些现代体系结构中，探测相邻单元所能产生的位置与额外的探测需要相比，前者是更为重要的因素，所以线性探测仍然是实用的，甚至是最佳选择。

跳房子散列的思路是，用事先确定的、对计算机的底层体系结构而言最优的一个常数，给探测序列的最大长度加个上界。这样做可以给出常数级的最坏查询时间，并且与布谷鸟散列一样，查询可以进行并行化，以同时检查可用位置的有限集。

如果某次插入要把一个新的项放到距离它的散列位置太远的地方，我们会很有效地掉头向散列位置走，替换掉潜在地项。如果足够谨慎，那么替换可以很快完成，并且保证那些被替换地项都不会放到距离它们的散列位置太远的地方。该算法在某种意义上是确定的，即给定一个散列函数，那些项或者是可以被替换的，或者不可以。后者意味着散列表可能太挤了，该做再散列了，但这只有在超过0.9的极高的装填因子下才会发生。对于装填因子为1/2的表来说，失败的概率几乎为0。

### 通用散列法

尽管散列表是很有效的，并且在装填因子适当的前提假设下每个操作都有固定的平均花销，但是其表现和分析却取决于散列函数具有以下两种性质：

1. 散列函数必须可在常数时间内计算。
2. 散列函数必须将各项均匀分布在数组单元中。

我们用M来表示TableSize。

**定义5.1**	如果对任意的 x &ne; y，H中有 h(x) = h(y)的散列函数h的个数至多为$|H|/M$，则一个散列函数是通用的。

注意这个定义对每一对项都成立，而不是对项求平均后成立。上述定义意味着，如果我们从一个通用族H中随机取一个散列函数，则任意两个不同项之间发生冲突的概率至多是1/M，并且当向表中加入N个项时，在起始点发生冲突的概率至多为N/M，或者是装填因子。

**定义5.2**	如果对任意的$ x_1$&ne;$y_1$，$ x_2$&ne;$y_2$，$\cdots$，$ x_k$&ne;$y_k$，H中有$h(x_1) = h(y_1)$,$h(x_2)=h(y_2),\cdots,h(x_k) = h(y_k)$的散列函数h的个数最多为$|H|/M^k$，则一个散列函数族H是k-通用的。

要设计一个简单的通用散列函数，我们将首先假设会把非常大的整数映射到从0到M-1范围内的比较小的整数。令p为比最大输入键值大的一个素数。我们的通用族H将由下列函数集组成，其中a和b是随机选取的：

H = { $H_{a,b}(x)=((ax+b) mod$  p) $mod$  M,其中$1\leq a\leq p-1,0\leq b \leq p-1$}

**定理5.4**	散列族H = { $H_{a,b}(x)=((ax+b) mod$  p)$mod$  M,其中$1\leq a\leq p-1,0\leq b \leq p-1$}是通用的。