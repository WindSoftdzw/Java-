# 处理器控制

### 1.RISC的组成

高性能计算机中需要的是能被并行访问的快速寄存器阵列。人们已经设计出专用的高速寄存器文件，它们可被集成到超大规模集成电路芯片中，也能作为一个独立的组件购买。这些设备也称为**多端口存储器组**，因为它带有几个能并行使用的访问端口。

**直通**处理器，因为可以想象指令从左侧的程序计数器流过该处理器，直至右侧的数据存储器（这个比喻在介绍流水线时也很有帮助）。这并不是一个完整的处理器，因为它没有实现立即数操作数或指令流控制（无条件分支和条件分支，子程序调用和返回）。它可以实现寄存器—寄存器操作、load和store等操作。

加速刚开始时程序计数器（PC）中保存了下一条将被执行的指令的地址。该地址被送往指令存储器并经自增器加4后送回PC，以指向下一条指令（假设指令字长32位，存储器按字节编址）。

指令被从指令存储器中取出，存储器中存放了当前指令对应的32位指令字。3个寄存器地址字段被送往寄存器文件，读出源寄存器S1和S2。这些寄存器的内容将被送往ALU，在那里被用来生成寄存器—寄存器操作（例如，与或、加、减）的结果，或者加到一起得到load或store指令的有效地址。

如果是寄存器—寄存器操作，ALU的结果将经过多路选择器写入寄存器文件的目的端口，从而被写回寄存器文件中。如果是load操作，ALU的输出将作为操作数的有效地址，用来从数据存储器中读出操作数，读出的操作数经过多路选择器写回寄存器文件。如果是store操作，寄存器文件中寄存器S2的内容将被送往数据存储器的数据输入。请注意，在这种实现方式里，store操作不能使用源寄存器S2作为地址指针。

##### （1）寄存器—寄存器数据传递

这个处理器执行的最简单的指令是寄存器—寄存器型，我们要做的全部工作就是将寄存器文件中两个源寄存器的值送往ALU，然后将运算结果写回寄存器文件的输入$D_{data}$（目的）。寄存器文件的输入端口$D_{data}$应增加一个多路选择器，因为要被写入寄存器文件的数据可能来自ALU，也可能是load操作中从数据存储器中读出的数据。请注意，这种操作和load/store操作都不需要PC控制模块，因为PC的输入是[PC]+4，指向顺序的下一条指令。

##### （2）单周期直通计算机的控制

现在简单地思考一下执行一条指令需要多长时间。在直通单周期计算机中，指令地平均执行时间并不重要。重要地是最长指令的执行时间，因为它决定了处理器的时钟周期时间。在强调一遍，最长指令决定了时钟周期时间，这意味着那些较简单的指令的执行时间比实际上长。那些复杂指令降低了性能。

load指令是执行时间最长的指令，因为必须先从存储器中读出操作码，访问寄存器文件以计算操作数的有效地址，利用执行单元将寄存器中的操作数与立即数相加，从数据存储器中取出操作数，最后，将操作数写回寄存器文件。下面是一个读周期内要完成的动作序列以及它们执行的时间：

1）PC建立时间（从时钟上升沿到PC输出稳定），$t_{pc}$。

2）取指令（从PC稳定到操作码稳定）,$t_{Imem}$。

3）读操作数（从操作码稳定到操作数稳定），$t_{RF}$。

4）ALU将S1与S2相加的时间，$t_{ALU}$。

5）从ALU计算出的地址值稳定到存储器操作数稳定的时间，$t_{Dmem}$。

6）存储器MPLX时间， $t_{MPLX}$。

7）寄存器文件中目的操作数的数据建立时间，$t_{RF}$。

因此，时钟周期时间是这些时间的总和：

$T_{cycle} = t_{PC}+t_{Imem}+t_{RF}+t_{ALU}+t_{Dmem}+t_{MPLX}+t_{RF_s}$

### 3.流水线简介

时钟周期是计算机中发生的最小事件，机器周期则是执行一条指令所需的时间。指令执行分为5个阶段：

**取指**——从系统存储器中读出指令ADD R0，R1，R2，并将程序计数器加4。

**译码**——对上一阶段从存储器中读出的指令译码（解码）。指令译码阶段的特点与指令集复杂度有关。定长编码的指令可以经过两级门电路快速译码，而复杂指令格式的译码可能需要基于ROM的查找表来实现。

**读操作数**——从寄存器R1和R2中读出指令指定的操作数，并将它们送入触发器。

**执行**——执行指令指定的操作。

**保存操作数**——将执行阶段的结果写回操作数的目的地址。它可能是片上寄存器，或外部存储器上的某个位置。在这个例子里，结果被存入寄存器R0中。

完成上述5个阶段中的每一个阶段都需要花费一定的时间（尽管所花费的时间一般是系统时钟周期的整数倍）。某些指令可能不需要全部5个阶段。例如，指令`CMP R1,R2`用R1减去R2来比较R1和R2的大小，并根据比较结果设置条件码，它不需要“保存操作数”这一阶段。

假设某个处理器按顺序完成这5个阶段。在任何时刻，该处理器只有20%的部分是活跃的。其余4个阶段共80%的部分是空闲的。例如，当指令处于执行阶段时，保存操作数逻辑正在等待结果，此时它什么也不做。一种更好的处理器设计方法是将指令执行的各个阶段重叠或**流水**执行。

指令执行被分为两个500ns的槽（slot），指令在第一个槽中被取出。在第二个500ns的槽中，进行读操作数、执行、结果写回等操作。当前指令的取指阶段一完成，下一条指令就立即开始执行，流水线就是这样实现的。采用这种方法，在不改变实现技术或加速时钟的情况下，可以高效地实现速度翻倍。获得速度的提升依靠的是更加高效地利用处理器地功能部件而不是提高时钟频率。

取指阶段被缩短为330ns，而指令地内部操作被分为两个阶段：一个是取操作数和执行阶段，紧跟其后的是保存操作数阶段。在这个例子里，三条指令的执行可以重叠在一起。

流水线的最优长度与实现技术有关，是关于体系结构和正在执行的代码的函数。正如我们将要看到的，特定类型指令（例如，分支以及其他控制程序流的指令）的处理方式在很大程度上影响了流水线的长度。取指周期的时间与取指操作数、执行和保存操作数等阶段的时间之和的比率，在决定流水线的最优长度上起了至关重要的作用。

SPARC T1的流水线有6个阶段。第二段被记作**线程选择**，它能从最多4个线程中选择一个运行。在这里要说的是，通过复用寄存器和PC，任何时刻处理器中都有可能同时存在几个线程，这是提高处理器性能的一种方法 。任一时间只有一个线程是活跃的并且正在被执行。其他线程处于休眠状态，只是以状态信息的形式存在于寄存器中。然而，如果发生了线程切换，那么当前线程使用的所有寄存器都将被换出，新线程的寄存器将被换入。当资源不可用时就进行线程切换（例如，由于处理器正在等待从存储器load操作完成），多线程技术可以借此提高性能。多线程技术还可以减弱延迟的影响。

##### （1）加速比

可以用**加速比**来描述流水线的性能；也就是说，带流水线系统与不带流水线系统的速度之比。如果系统将操作划分为n个流水段，那么完成第一个操作将花费n个时钟周期。此后，每个时钟周期将完成一个新的操作。一旦流水线被充满，每个时钟周期都会完成一个新的操作。但实际上，由于某些原因，这是无法做到的。其中最重要的两个原因就是：分支对流水线的影响，以及数据依赖的影响（例如，当一条指令需要使用之前一条指令的结果，而那个结果还没有计算出来并且没被写回）。

若有i条指令在该流水线上执行，那么需要花费i+（n-1）个周期。如果不使用流水线，系统将需要使用n·i个周期。因此加速比为

$S = \frac {n·i} {i+(n-1)} = \frac {n} {1+\frac{n-1}{i}}$

##### (2)冒险

**数据冒险**是指一条指令的处理依赖它之前且依然在流水线中的一条指令所产生的数据的情形。**控制冒险**发生在分支转移成功并且流水线中所有已经部分被执行的指令都不得不被丢弃的时候。

另外一种冒险是**结构冒险**，它发生在当两个事件同时请求相同的资源时。如果两条指令试图同时访问存储器且存储器不支持同时访问时，存储器会产生结构冒险。

当处理器遇到一个转移成功的**分支指令**时，它必须将一个新值重新载入程序计数器；即分支**目标地址**。将一个不连续的地址重新加载到程序计数器中意味着流水线中完成的所有有用的工作必须作废，因为紧接在分支之后的指令将不会执行。请注意，计算目标地址并不是一项不重要的工作，因为绝大多数微处理器都使用了**相对PC寻址**。一个典型的分支，比如`BBQ XYZ`，没有使用绝对地址，而是使用一个以相对程序寄存器值的字节数表示的相对目标地址。因此，目标地址必须通过将分支指令中的偏移量与程序计数器的值相加计算出来。显然，这会花费一些时间而且新的目的地址可能直到指令周期的末尾才是可用的。

分支指令并不是唯一的会在流水线系统中引起问题的指令。子程序调用、返回、自陷和异常等指令都会改变指令执行的顺序，如果分支延迟完成还有可能引入气泡。

当流水线中的数据作废了或者流水线由于引入空闲状态而暂停时，我们就会说产生了一个**气泡**。另一个描述气泡的术语是**流水线暂停**。流水线越长，遇到分支时要作废的指令也就越多。

###### 延迟分支

由于程序流控制指令出现频率较高，任何使用流水线的真实处理器都必须采取一定措施来解决这类指令所引起的气泡问题。Berkeley RISC机器通过作废紧接在分支之后的指令以减少气泡的影响。也就是说，分支之后的指令总会被执行。

不幸的是，不可能总是像这样在分支之后放入一条有用指令。这时，编译器必须在分支之后插入一个**空操作**指令，这将不可避免地带来流水线。

###### 数据冒险

在**当前指令**的输出依赖于前面一条还未执行完的指令的结果时会引起**数据相关**。数据冒险是由于要保持指令执行顺序的需要而产生的。

按照引起数据冒险的操作顺序，数据冒险可被分成3类，分别是：

RAW	读后写	（也叫真数据相关）

WAW	写后写	（也叫输出相关）

WAR	写后读	（也叫反数据相关）

RAW是最重要的冒险形式，此时写数据之后会读该数据。

遇到RAW冒险，在指令i的写结果完成之前指令i+1无法读出操作数。

因此，当指令i+1等待它的数据时必须向流水线中插入气泡。写后读（WAR）冒险与读后写（RAW）冒险有非常明显的不同；存在读后写冒险的指令对的变量之间没有语法上的依赖。

正常情况下不会引起WAR冒险。当然，若第二条指令在第一条指令之前执行，则会产生冒险。

如何在两条连续指令之间检测RAW冒险。比较器将前一条指令的目的地址和当前指令的两个源地址进行比较。假如它们其中某一对（或者两对都）相同，则直接从执行单元而不是寄存器文件中复制所需的操作数。

内部转发的实现：结果通过两个多路选择器直接从ALU的输出送入两个源操作数锁存器中。多路选择器决定了源操作数的输入是来自寄存器文件还是ALU。而在实践中，内部定向会更加复杂，因此必须考虑中断和异常处理。

### 4.分支和分支开销

一条分支指令，在转移成功时，会将一个新的非顺序的值载入处理器的程序计数器中，流水线必须由分支目标地址及其后面的指令重新充满。执行一个引起非顺序控制流的操作所花费的时间被称作**分支开销**。

有几种类型的指令会改变控制流；比如无条件分支、条件分支、子程序调用以及子程序返回。处理器内部产生的自陷和异常以及外部产生的中断也会改变控制流。

无条件分支总会转移成功，并强制流水线从目标弟子处继续执行。无条件分支等价于高级语言的goto语句，并且其结果在**编译时**就可以知道了。

条件分支的结果由处理器条件码寄存器中的一个或多个标志位（或一些等价的机制）决定，因此直到**运行时**才能知道。条件分支可能转移成功。当分支转移不成功时，分支结果有时候被称作是**直线的**，因为紧挨着分支的下一条指令会被执行。

子程序调用是一种会保存返回地址的无条件分支。同样，子程序返回是一种寄存器或栈中取出目标地址的无条件分支。

**结果状态方法**非常适合那些严格的顺序系统（即测试数据、设置条件、测试条件和根据条件进行分支）。带有多个执行单元的系统无法支持一个简单的“结果状态分支”机制，因为结果状态可能依赖**乱序执行**。

##### （1）流水线中分支的影响

分支通过引入气泡或者流水线暂停降低了流水线体系结构的效率。流水线没有充满的这段时间（分支之后）叫作流水线的**启动延迟**，这种引起一个气泡的分支影响被称作**指令误区开销**。

##### （2）分支开销

若要减少分支指令对流水线处理器性能的影响。我们需要描述系统性能的**度量**或者**参数**。由于不清楚某个给定程序中有多少分支，或每条分支是否会转移成功，我们不得不为系统构建一个**概率模型**。我们进行如下假设：

1. 每个非分支指令都在一个周期内执行
2. 给定指令是分支的概率为$p_b$。
3. 分支转移执行的概率为$p_t$。
4. 如果分支转移成功，额外开销为b个周期。
5. 如果分支转移不成功，则没有额外开销，并且仅需1个周期。

由于一条指令是分支的概率与它不是分支的概率之和必定为1，可以认为一条指令不是分支的概率为$1-p_b$。

在程序执行期间完成一条指令所需的平均周期数为非分支指令的CPI加上转移成功的分支指令的CPI，再加上转移不成功的分支指令的CPI，即：

$T_{ave}=(1-p_{b})·p_t·(1+b)+p_b(1-p_t)·1=1+p_bp_tb$

表达式$1+p_bp_tb$表明分支指令的数量、分支转移成功的概率以及每条分支指令的开销都会影响分支开销。若用$p_e$(有效分支概率)替代$p_bp_t$，则每条指令所花的平均周期数为$1+p_eb$。RISC处理器的效率E，可被定义为：

​									$E= \frac {没有分支指令时的平均CPI}{有分支指令时的平均CPI} \times 100 \%$

即

​									$E=\frac {1} {1+p_eb} \times 100 \%$

仅当分支转移成功的概率很低时流水线才是高效的。当分支开销b的值较大时，效率随$p_e$的增加而极具滑落。如果流水线很长（即b较大），即使代码中一个偶然出现的分支也会带来很多性能损失。

##### （4）延迟分支

最简单的处理分支方式就是什么都不做；即一检测到分支指令就**冻结**流水线并，而在分支处理完后**解冻**流水线，并从目标地址处继续取指。

转移不成功的分支会引入一个时钟周期的额外开销，而转移成功的 分支会引入3个时钟周期的额外开销。因此，每条指令的平均周期数，

​					$T_{ave} = 1·(1-P_b)+2·P_b(1-P_t)+4·P_bP_t=1+P_b+2P_bP_t$

如果$P_b$取值为0.2，$P_t$取值为0.8（20%指令时分支指令，80%分支会转移成功),我们会得到

​					$T_{ave}=1+0.2+2\times0.2\times0.8=1.52$

这个等式表示分支指令使性能下降了52%。

一些处理器实现了**延迟分支**因为在分支指令执行结束时，紧挨着分支指令的下一条指令几乎也以及执行结束，显然，让这条执行完似乎是很合理的。也就是说，可以将一条指令放在分支指令之后，并且这条指令总是与分支指令并执行。

当分支转移不成功时，分支开销为0，因为指令i+1总会被执行，而且流水线不会暂停，因为流水线不会被冻结。而当分支转移成功时，因为指令i+1总会被执行，所以仅有两个时钟周期的损失。

​					$T_{ave} = 1·(1-P_b)+1·P_b(1-P_t)+3·P_bP_t=1+2P_bP_t$

若$P_b$取值为0.2，$P_t$为0.8，则有$T_{ave}=1+2\times0.2\times0.8=1.32$，这表明与简单冻结流水线相比性能得到了一定的提升。

如果编译器能够找到一条独立的指令并将其放在分支指令之后，那么延迟分支机制将是有效的。术语“独立的”强调，不能将任意一条指令放在分支指令之后。例如，不能使用一条影响分支结果的指令。被选出的指令应该是那些无论分支转移是否成功都会被执行的指令。如果没有可用的指令，编译器必须输入一条NOP指令（空操作）以保持流水线继续运转。在大约60%的情况下，可以找到一条适合放在分支之后的指令。

HP-PA的分支之后有一条指令的延迟。HP-PA的分支指令含有1位的**取消字段**，它决定了如何处理紧跟在分支之后那条指令。当该位被置为1时，取消位允许分支指令有条件地根据分支结果忽略延迟槽内的指令。请考虑一个位于循环结构末尾的分支。这个分支一般都会转移成功，仅在退出循环时转移不成功。通过使延迟槽中指令的执行依赖于分支转移是否成功，我们可以将一条循环指令放入延迟槽中。当分支转移到循环开始处时，循环指令被执行。

DeRosa和Levy使用术语“基本块大小”表示连续的分支指令间的平均指令数。基本块的平均长度为$1/(P_b·P_t)$，其中$P_b$表示一条指令是分支指令的概率，$P_t$表示分支转移成功的概率。他们声称，在基本块较大的计算机上，延迟分支的作用相对较小。

### 5.分支预测

当分支转移成功时，一些本不应该被执行的指令已经开始在流水线上执行，因此这些指令将被作废（这一过程叫作**清空流水线**），并会损失一些时钟周期。如果在一条分支指令执行之前我们就已知到它会转移成功，就可以将**分支目标地址**处的指令送入流水线。

对于BRA N那样的无条件分支指令，预测机制的效果很好。条件分支则会带来一些问题。

预测一个有两种可能输出的系统的行为，会有4种可能：

1. 预测分支转移成功且分支转移成功——正确输出。
2. 预测分支转移成功且分支转移不成功——不正确输出。
3. 预测分支转移不成功且分支转移不成功——正确输出。
4. 预测分支转移不成功但分支转移成功——不正确输出。

可以用**分支执行时间**或**分支开销**来描述分支带来的性能损失。分支执行时间是指执行分支指令所需的时钟周期总数；分支开销则是指相比于无性能损失情况的额外时钟周期数，即分支开销=分支执行时间-1。

假设一条指令是分支指令的概率为$p_b$。$p_b$的值可以通过测量静态或动态指令数来得到。其次需要直到分支指令转移成功的概率为$p_t$。最后，需要直到预测的精确性，$p_c$是分支预测正确的概率。

一条分支指令的执行时间（即所需的时钟周期数）为

​			$C_{ave}=a(P_{预测转移且转移})+b(P_{预测不转移但转移}+c(P_{预测转移但没有转移}+d(P_{预测不转移且没有转移})))$

一条分支指令的执行时间为$(1-p_b)+p_bC_{ave}$。

如果一个事件或它的对立事件一定会发生，则它们的概率之和为1，利用这一原理可得

$(1-p_b)$=一条指令不是分支指令的概率。

$(1-p_t)$=一个分支转移不成功的概率。

$(1-p_c)$=预测不正确的概率。

每条分支指令的平均CPI的计算方法如下，沿着每一条可能的路径，将发生的概率与所需的执行时间相乘，然后将所有路径的时间相加；即

​		$C_{ave}=a·(p_i·p_c)+bp_i·(1-p_c)+c·(1-p_t)·(1-p_c)+d·(1-p_t)·p_c$

这个表达式并没有明显的帮助。可以做两个假设帮我们简化这个表达式。第一个假设为a=d=N。另一个简化是b=c=B。因此，平均CPI为$1-p_b+p_b·C_{ave}$；即

​		$(1-p_b)+p_b·[N·p_i·p_c+B·P_i·(1-p_c)+B·(1-p_t)·(1-p_c)+N·(1-p_t)·p_c] = (1-p_b)+p_b·[1·p_c+B·(1-p_c)]$

若进一步假设预测正确时不会产生任何开销（即N = 1），则有：

​		$(1-p_b)+p_b·[1·p_c+B·(1-p_c)]$

###### 静态和动态分支预测

实现分支预测有两种方法，分别是**静态分支预测**和**动态分支预测**。**静态分支预测**假设分支总会转移或者总不转移。对真实代码的观测表明分支指令有超过50%的机会会转移成功，因此，最简单的静态分支预测机制是，只要一检测出分支指令就从分支目标地址处取出下条指令。

一种更好地静态预测分支结果的方法是观察分支在真实代码中的行为，因为一些分支指令相比其他分支指令更频繁或者更少地发生预测。也就是说，测试大量的代码，确定编译器如何使用这些分支，并在此基础上进行分支预测。Lilja称，用操作码来预测分支的结果可以达到75%的准确率。

### 6.动态分支预测

有很多种方法可以实现运行时分支预测机制。预测未来就是用关过去的信息对未来做出**有意义的猜测**。我们可以设置一个标志将分支的最后一次执行结果设为该标志的值。如果一个分支**转移不成功**，则将该标志置位N并预测该分支在下一次执行时转移不成功。换句话说，这一预测机制占用位存储空间，并且它的预测结果就是分支最后一次执行的结果。尽管这一策略对循环来说可能比较有效，但当分支方向频繁改变时预测结果将会非常的差。

如果使用两位分支历史信息，则可以得到一个更复杂的预测器。实际上，当增加更多的信息位时，预测器能够做出更好的预测。

##### （1）分支目标缓冲

一种叫作**分支目标缓冲或者分支目标Cache**的专用存储器是一个与减少分支开销有关的重要概念，它保存了当前程序种**活跃**的分支指令的信息。Cache是一个保存了频繁使用的数据的高速存储器，它的访问速度比主存快得多。被缓存的信息包括：分支地址，分支的预测结果，分支历史，分支目标地址，以及目标地址的指令复本。

